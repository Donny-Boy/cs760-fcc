{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_df(X,label):\n",
    "    x = X.copy()\n",
    "    y = label.copy()\n",
    "    df = pd.concat([x,y],axis=1)\n",
    "    num_pos = df.loc[df['not_commenter']== 1].shape[0]\n",
    "    num_neg = df.loc[df['not_commenter']==-1].shape[0]\n",
    "    \n",
    "    if num_pos<num_neg:\n",
    "        df1=df.loc[df['not_commenter']==-1].sample(n=num_pos)\n",
    "        df2=df.loc[df['not_commenter']== 1]\n",
    "    else:\n",
    "        df1=df.loc[df['not_commenter']==-1]\n",
    "        df2=df.loc[df['not_commenter']== 1].sample(n=num_neg)\n",
    "    \n",
    "    df = pd.concat([df1,df2])\n",
    "    \n",
    "    y = df['not_commenter'].to_frame()\n",
    "    df = df.drop(columns=['not_commenter'])\n",
    "    \n",
    "    return df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-e36291e880c9>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-e36291e880c9>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    plt.savefig('figures/'filename+'.png')\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class LR:\n",
    "    \n",
    "    \"\"\"\n",
    "    X: an array containing the X for training and testing\n",
    "    Y: an array containing the labels for training and testing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,X,Y,cv=10,test_size=0.1):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        self.model = LogisticRegressionCV(cv=cv,solver='lbfgs')\n",
    "        self.trainX, self.testX, self.trainy, self.testy = train_test_split(X, Y, test_size=test_size, random_state=2)\n",
    "    \n",
    "    def train(self):\n",
    "        print(\"Beginning trainning...\")\n",
    "        self.model.fit(self.trainX,self.trainy)\n",
    "        print(\"Training complete.\\nAverage Score on 10-fold Cross Validation:\")\n",
    "        print(\"\\t %.4f %%\\n\" % (self.model.score(self.trainX,self.trainy)*100))\n",
    "    \n",
    "    def test(self):\n",
    "        print(\"Beginning testing...\")\n",
    "        test_score = self.model.score(self.testX,self.testy)\n",
    "        print(\"Testing complete.\\nAverage Score on 10-fold Cross Validation:\")\n",
    "        print(\"\\t %.4f %%\\n\" % (test_score*100))\n",
    "        \n",
    "    def roc(self,filename = None):\n",
    "        print(\"Plotting ROC Curve\")\n",
    "        scorey = self.model.decision_function(self.testX)\n",
    "        n_classes = self.testy.shape[0]\n",
    "        \n",
    "        fpr, tpr, _ = roc_curve(self.testy, scorey)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        self.fpr = fpr\n",
    "        self.tpr = tpr\n",
    "\n",
    "        plt.figure()\n",
    "        \n",
    "        lw = 2\n",
    "        \n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show();\n",
    "        \n",
    "        if filename != None:\n",
    "            print(\"Saving \"+filename+\"_ROC.png\")\n",
    "            plt.savefig('figures/'+filename+'.png')\n",
    "            df1 = pd.DataFrame(fpr,columns=['FPR'])\n",
    "            df2 = pd.DataFrame(tpr,columns=['TPR'])\n",
    "            df = pd.concat([df1,df2],axis=1)\n",
    "            print(\"csv/Saving \"+filename+\"_ROC.csv\")\n",
    "            df.to_csv(filename+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../VarianceAnalysis/db/Base_v0.csv')\n",
    "y = pd.read_csv('../VarianceAnalysis/db/Y.csv')\n",
    "\n",
    "# X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "a = LR(X,y)\n",
    "a.train()\n",
    "a.test()\n",
    "a.roc(filename='Base_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/Base_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "ua = LR(X,y)\n",
    "ua.train()\n",
    "ua.test()\n",
    "ua.roc(filename='uBase_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseCampaign_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "# X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "b = LR(X,y)\n",
    "b.train()\n",
    "b.test()\n",
    "b.roc(filename='BaseCampaign_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseCampaign_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "ub = LR(X,y)\n",
    "ub.train()\n",
    "ub.test()\n",
    "ub.roc(filename='uBaseCampaign_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseCampaignBin_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "# X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "c = LR(X,y)\n",
    "c.train()\n",
    "c.test()\n",
    "c.roc(filename='BaseCampaignBin_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseCampaignBin_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "uc = LR(X,y)\n",
    "uc.train()\n",
    "uc.test()\n",
    "uc.roc(filename='BaseCampaignBin_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseBow_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "# X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "d = LR(X,y)\n",
    "d.train()\n",
    "d.test()\n",
    "d.roc(filename='BaseBow_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseBow_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "ud = LR(X,y)\n",
    "ud.train()\n",
    "ud.test()\n",
    "ud.roc(filename='uBaseBow_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseBowBin_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "# X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "e = LR(X,y)\n",
    "e.train()\n",
    "e.test()\n",
    "e.roc(filename='BaseBowBin_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('db/BaseBowBin_v0.csv')\n",
    "y = pd.read_csv('db/Y.csv')\n",
    "\n",
    "X,y = undersample_df(X,y)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()\n",
    "\n",
    "ue = LR(X,y)\n",
    "ue.train()\n",
    "ue.test()\n",
    "ue.roc(filename='uBaseBowBin_v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
